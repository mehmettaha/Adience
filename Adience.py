# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19uNGb4oatedwQHQHvy51UE26Tz8iOC_3
"""

from google.colab import files

!mkdir ~/.kaggle
!touch ~/.kaggle/kaggle.json

api_token = {"username":"mehmettahaaydn","key":"2b8ffc11699c5ee48696b3e718c93f6e"}

import json

with open('/root/.kaggle/kaggle.json', 'w') as file:
    json.dump(api_token, file)

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d ttungl/adience-benchmark-gender-and-age-classification

from zipfile import ZipFile
file = ZipFile('adience-benchmark-gender-and-age-classification.zip')
file.extractall('data')
file.close()

import os

#!/usr/bin/env python
# coding: utf-8

# In[1]:


import cv2 
import numpy as np
import pandas as pd
import keras
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers.core import Activation
from keras.layers.core import Flatten
from keras.layers.core import Dropout
from keras.layers.core import Dense
from keras.models import Sequential
from keras import backend as K
from keras.utils import np_utils
from keras.optimizers import SGD
from sklearn.metrics import classification_report
import os
from sklearn.model_selection import train_test_split
#学習に使うblobのピクセル数
pixel = 56


# **パスの入力:こちらにデータフォルダのパスを入力する**

# In[2]:


datapath = 'data/AdienceBenchmarkGenderAndAgeClassification'


# **モデルの構築**  
# こちらで学習モデルの設計を作ります。

# In[3]:


class zeka:

    def build(width, height, depth, classes):

        model = Sequential()
        inputShape = (height, width, depth)
        chanDim = -1  
        
        model.add(Conv2D(96, (7, 7), padding="same",input_shape=inputShape))
        model.add(Activation("relu"))
        model.add(BatchNormalization(axis=chanDim))
        

        model.add(Conv2D(218, (5, 5), padding="same",input_shape=inputShape))
        model.add(Activation("relu"))
        model.add(BatchNormalization(axis=chanDim))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.25)) 

        
        model.add(Conv2D(384, (3, 3), padding="same",input_shape=inputShape))
        model.add(Activation("relu"))
        model.add(BatchNormalization(axis=chanDim))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.25)) 
        
        model.add(Flatten())
        model.add(Dense(512))
        model.add(Activation("relu"))
        model.add(BatchNormalization())
        model.add(Dropout(0.25))
        
        model.add(Dense(216))
        model.add(Activation("relu"))
        model.add(BatchNormalization())
        model.add(Dropout(0.25))

        model.add(Dense(classes))
        model.add(Activation("softmax"))

        return model



alldata = pd.DataFrame()
for i in os.listdir(datapath):
    if i.endswith('.txt'):
        read = pd.read_csv(os.path.join(datapath, i), sep = '\t')
        alldata = alldata.append(read)


path = os.path.join(datapath, 'faces')
columns = ['photo', 'name', 'face_id', 'file']
photos = pd.DataFrame(columns = columns)
for folder in os.listdir(path):
    for file in os.listdir(os.path.join(path, folder)):
        if file.endswith('jpg'):
            photo = pd.Series()
            photo['photo'] = os.path.join(path, folder, file)
            phoname = file.split('.')
            photo['name'] = phoname[-2]
            photo['face_id'] = np.int64(phoname[-3])
            photo['file'] = file
            photos = photos.append(photo, ignore_index = True)

photos = photos.sort_values(['name','face_id'])

labelNames = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']
path = os.path.join(datapath, 'AdienceBenchmarkGenderAndAgeClassification/faces')
columns = ['photo',]
testphotos = pd.DataFrame(columns = columns)
for folder in os.listdir(path):
  if not folder.endswith('Store'):
    for file in os.listdir(os.path.join(path, folder)):
        if file.endswith('jpg'):
            photo = pd.Series()
            photo['photo'] = file
            testphotos = testphotos.append(photo, ignore_index = True)

alldata = alldata.reset_index(drop = True)
photos = photos.reset_index(drop = True)

merged = alldata.merge(photos, how = 'inner', right_index = True, left_index = True)

merged2 = merged[['photo', 'name', 'face_id_x', 'age', 'file']].reset_index(drop = True)

newtrainY = list()
for num, i in enumerate(merged2['age']):
    if i == '(0, 2)':
        newtrainY.append([1,0,0,0,0,0,0,0])
    elif i == '(4, 6)':
        newtrainY.append([0,1,0,0,0,0,0,0])
    elif i == '(8, 12)':
        newtrainY.append([0,0,1,0,0,0,0,0])
    elif i == '(15, 20)':
        newtrainY.append([0,0,0,1,0,0,0,0])
    elif i == '(25, 32)':
        newtrainY.append([0,0,0,0,1,0,0,0])
    elif i == '(38, 43)':
        newtrainY.append([0,0,0,0,0,1,0,0])
    elif i == '(48, 53)':
        newtrainY.append([0,0,0,0,0,0,1,0])
    elif i == '(60, 100)':
        newtrainY.append([0,0,0,0,0,0,0,1])
    else:
        newtrainY.append(None)
merged2['onehot'] = newtrainY
merged2 = merged2.dropna()

Xdata = list()
for i, (_, row) in enumerate(merged2.iterrows()):
    a = cv2.imread(row['photo'])
    #a = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)
    blobraw = cv2.dnn.blobFromImage(a, 1/255, (pixel,pixel), (100,106,120), True)
    Xdata.append(blobraw)
merged2['blob'] = Xdata

indexlist = list()
testlist = list(testphotos['photo'])
for i, row in merged2.iterrows():
  if row['file'] in testlist:    
    indexlist.append(i)

testdata = merged2.loc[indexlist]
traindata = merged2.drop(indexlist)

np.concatenate(traindata['blob'].to_numpy()).shape

trainX = np.concatenate(traindata['blob'].to_numpy()).reshape(len(traindata), pixel, pixel, 3)
trainY = np.concatenate(traindata['onehot'].to_numpy()).reshape(len(traindata), 8)
testX = np.concatenate(testdata['blob'].to_numpy()).reshape(len(testdata), pixel, pixel, 3)
testY = np.concatenate(testdata['onehot'].to_numpy()).reshape(len(testdata), 8)

model = zeka.build(width=pixel, height=pixel, depth=3, classes=8)
opt = SGD(lr=0.01, momentum=0.9)
model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

# 学習開始
model.fit(trainX, trainY, validation_split = 0.1, batch_size=32, epochs=50)


# In[18]:





# 結果の報告

# In[27]:


preds = model.predict(testX)
print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1), target_names=labelNames))


# 任意の写真でAIを試す



oneoff = 0
for i in range(len(preds)):
    if abs(preds[i].argmax() - testY[i].argmax() ) <= 1:
            oneoff += 1
print('One-Off accuracy is ' + str(oneoff/len(preds)))

preds = model.predict(testX)
print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1), target_names=labelNames))


# 任意の写真でAIを試す



oneoff = 0
for i in range(len(preds)):
    if abs(preds[i].argmax() - testY[i].argmax() ) <= 1:
            oneoff += 1
print('One-Off accuracy is ' + str(oneoff/len(preds)))



#任意の写真を試すに以下の変数に写真のパスを入力する
testphoto = 'dede.jpg'
def prepare(path):
    img = cv2.imread(path)
    blobraw = cv2.dnn.blobFromImage(img, 1/255, (pixel,pixel), (90,110,120), True).reshape(1, pixel, pixel, 3)
    return blobraw
print(labelNames[model.predict(prepare(testphoto)).argmax(axis = 1)[0]])

model.save('basit200.h5')
import os
os.listdir('')

"""# New Section

# New Section
"""